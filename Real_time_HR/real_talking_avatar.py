'''import os
import subprocess
import librosa
from datetime import datetime
from dotenv import load_dotenv
from try_TTS_Yandex import text_to_audio  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
from try_generation_Yandex import generate_text  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
from openai_whisper_STT import transcribe_wav_to_text  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
import sounddevice as sd
from scipy.io.wavfile import write

# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç—å –∫ FFmpeg —É–∫–∞–∑–∞–Ω
os.environ["PATH"] += os.pathsep + r"E:\ffmpeg-7.1-full_build\bin"

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
GREETINGS_TEMP = "GREETINGS_TEMP"
TEMP_INFERENCE = "TEMP_INFERENCE"
os.makedirs(GREETINGS_TEMP, exist_ok=True)
os.makedirs(TEMP_INFERENCE, exist_ok=True)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ
def record_audio(output_path, duration=10, sample_rate=44100):
    print("üé§ –ù–∞—á–Ω–∏—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å...")
    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)
    sd.wait()
    write(output_path, sample_rate, audio)
    print(f"üéß –ê—É–¥–∏–æ –∑–∞–ø–∏—Å–∞–Ω–æ: {output_path}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–º–µ–Ω—ã –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏ –≤ –≤–∏–¥–µ–æ
def replace_audio_in_video(template_video, new_audio, output_video):
    """
    –ó–∞–º–µ–Ω—è–µ—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º –≤–∏–¥–µ–æ.
    :param template_video: –ü—É—Ç—å –∫ —à–∞–±–ª–æ–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ.
    :param new_audio: –ü—É—Ç—å –∫ –Ω–æ–≤–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param output_video: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    command = (
        f'ffmpeg -i "{template_video}" -i "{new_audio}" '
        f'-c:v copy -map 0:v:0 -map 1:a:0 -shortest "{output_video}" -y'
    )
    try:
        subprocess.run(command, check=True, shell=True)
        print(f"üé• –í–∏–¥–µ–æ —Å –Ω–æ–≤—ã–º –∞—É–¥–∏–æ —Å–æ–∑–¥–∞–Ω–æ: {output_video}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {e}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ –ø–æ–¥ –∞—É–¥–∏–æ
def adjust_video_duration(video_path, audio_path, output_video):
    """
    –ò–∑–º–µ–Ω—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –æ–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ.
    :param video_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ.
    :param audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param output_video: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
    audio_duration = librosa.get_duration(path=audio_path)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–∞–Ω–¥—É FFmpeg –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ
    command = (
        f'ffmpeg -stream_loop -1 -i "{video_path}" -i "{audio_path}" '
        f'-c:v libvpx-vp9 -t {audio_duration} -c:a libopus "{output_video}" -y'
    )
    try:
        subprocess.run(command, check=True, shell=True)
        print(f"üé¨ –í–∏–¥–µ–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ –∞—É–¥–∏–æ: {output_video}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {e}")

def process_user_input():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–¥–µ–æ–æ—Ç–≤–µ—Ç–∞.
    """
    # === –®–∞–≥ 1: –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ ===
    audio_file = os.path.join(GREETINGS_TEMP, "user_input.wav")
    record_audio(audio_file)

    # === –®–∞–≥ 2: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ ===
    print("[STT] –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...")
    user_text = transcribe_wav_to_text(audio_file)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
    print(f"[STT] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {user_text}")

    # === –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é YandexGPT ===
    print("[AI] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
    response_text = generate_text(user_text)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º YandexGPT
    print(f"[AI] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {response_text}")

    # === –®–∞–≥ 4: –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ ===
    print("[TTS] –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏...")
    session_id = os.urandom(4).hex()
    audio_path = os.path.join(GREETINGS_TEMP, f"response_audio_{session_id}.ogg")
    audio_bytes = text_to_audio(response_text, voice="zahar")  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å "zahar"
    with open(audio_path, "wb") as f:
        f.write(audio_bytes)
    print(f"[TTS] –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {audio_path}")

    # === –®–∞–≥ 5: –ü–æ–∏—Å–∫ —à–∞–±–ª–æ–Ω–∞ –≤–∏–¥–µ–æ ===
    template_videos = [f for f in os.listdir(GREETINGS_TEMP) if f.endswith(".webm")]
    if not template_videos:
        raise FileNotFoundError(f"–®–∞–±–ª–æ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ø–∞–ø–∫–µ: {GREETINGS_TEMP}")

    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω
    template_video_name = template_videos[0]
    template_video = os.path.join(GREETINGS_TEMP, template_video_name)
    print(f"[VIDEO] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —à–∞–±–ª–æ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: {template_video}")

    # === –®–∞–≥ 6: –ê–¥–∞–ø—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ –ø–æ–¥ –Ω–æ–≤—É—é –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É ===
    adjusted_video = os.path.join(GREETINGS_TEMP, f"adjusted_video_{session_id}.webm")
    adjust_video_duration(template_video, audio_path, adjusted_video)

    # === –®–∞–≥ 7: –ó–∞–º–µ–Ω–∞ –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏ ===
    output_video = os.path.join(TEMP_INFERENCE, f"final_response_{session_id}.webm")
    replace_audio_in_video(adjusted_video, audio_path, output_video)

    # === –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ ===
    # –ó–¥–µ—Å—å –±–æ–ª—å—à–µ –Ω–µ—Ç —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤, —Ç–∞–∫ –∫–∞–∫ –æ–Ω–∏ –Ω—É–∂–Ω—ã –¥–ª—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    print("‚ö†Ô∏è –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.")

    return output_video

if __name__ == "__main__":
    try:
        video_path = process_user_input()
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ò—Ç–æ–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ: {video_path}")
    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
'''
import numpy as np
import os
import subprocess
import librosa
from datetime import datetime
from dotenv import load_dotenv
from try_TTS_Yandex import text_to_audio  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏
from try_generation_Yandex import generate_text  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
from openai_whisper_STT import transcribe_wav_to_text  # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
import sounddevice as sd
from scipy.io.wavfile import write
import time  # –î–æ–±–∞–≤–ª—è–µ–º –º–æ–¥—É–ª—å –¥–ª—è –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏

# –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –ø—É—Ç—å –∫ FFmpeg —É–∫–∞–∑–∞–Ω
os.environ["PATH"] += os.pathsep + r"E:\ffmpeg-7.1-full_build\bin"

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ü—É—Ç–∏ –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è–º
GREETINGS_TEMP = "GREETINGS_TEMP"
TEMP_INFERENCE = "TEMP_INFERENCE"
os.makedirs(GREETINGS_TEMP, exist_ok=True)
os.makedirs(TEMP_INFERENCE, exist_ok=True)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ
import os
import sounddevice as sd
from scipy.io.wavfile import write


def record_audio(output_path, sample_rate=44100):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –∞—É–¥–∏–æ –¥–æ —Ç–µ—Ö –ø–æ—Ä, –ø–æ–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–∂–º–µ—Ç Enter.
    :param output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ.
    :param sample_rate: –ß–∞—Å—Ç–æ—Ç–∞ –¥–∏—Å–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 44100 –ì—Ü).
    """
    print("üé§ –ù–∞—á–Ω–∏—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å... –î–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏ –Ω–∞–∂–º–∏—Ç–µ Enter –≤ –∫–æ–Ω—Å–æ–ª–∏.")

    # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã—Ö
    audio_frames = []

    # –§—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –≤—ã–∑–æ–≤–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏ –∞—É–¥–∏–æ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    def callback(indata, frames, time, status):
        if status:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: {status}")
        audio_frames.append(indata.copy())  # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±—É—Ñ–µ—Ä

    # –ù–∞—á–∏–Ω–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—É—é –∑–∞–ø–∏—Å—å
    with sd.InputStream(callback=callback, channels=1, samplerate=sample_rate):
        input("üéß –ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏...\n")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –∞—É–¥–∏–æ –≤ –æ–¥–∏–Ω –º–∞—Å—Å–∏–≤
    audio_data = np.concatenate(audio_frames, axis=0)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–∞–ø–∏—Å–∞–Ω–Ω–æ–µ –∞—É–¥–∏–æ –≤ —Ñ–∞–π–ª
    write(output_path, sample_rate, audio_data)
    print(f"üéß –ê—É–¥–∏–æ –∑–∞–ø–∏—Å–∞–Ω–æ: {output_path}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–º–µ–Ω—ã –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏ –≤ –≤–∏–¥–µ–æ
def replace_audio_in_video(template_video, new_audio, output_video):
    """
    –ó–∞–º–µ–Ω—è–µ—Ç –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º –≤–∏–¥–µ–æ.
    :param template_video: –ü—É—Ç—å –∫ —à–∞–±–ª–æ–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ.
    :param new_audio: –ü—É—Ç—å –∫ –Ω–æ–≤–æ–º—É –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param output_video: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    command = (
        f'ffmpeg -i "{template_video}" -i "{new_audio}" '
        f'-c:v copy -map 0:v:0 -map 1:a:0 -shortest "{output_video}" -y'
    )
    try:
        subprocess.run(command, check=True, shell=True)
        print(f"üé• –í–∏–¥–µ–æ —Å –Ω–æ–≤—ã–º –∞—É–¥–∏–æ —Å–æ–∑–¥–∞–Ω–æ: {output_video}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ: {e}")

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ –ø–æ–¥ –∞—É–¥–∏–æ
def adjust_video_duration(video_path, audio_path, output_video):
    """
    –ò–∑–º–µ–Ω—è–µ—Ç –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤–∏–¥–µ–æ, —á—Ç–æ–±—ã –æ–Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞–ª–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞—É–¥–∏–æ.
    :param video_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É –≤–∏–¥–µ–æ.
    :param audio_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
    :param output_video: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞.
    """
    # –ü–æ–ª—É—á–∞–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞—É–¥–∏–æ
    audio_duration = librosa.get_duration(path=audio_path)

    # –°–æ–∑–¥–∞–µ–º –∫–æ–º–∞–Ω–¥—É FFmpeg –¥–ª—è –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–∏–¥–µ–æ
    command = (
        f'ffmpeg -stream_loop -1 -i "{video_path}" -i "{audio_path}" '
        f'-c:v libvpx-vp9 -t {audio_duration} -c:a libopus "{output_video}" -y'
    )
    try:
        subprocess.run(command, check=True, shell=True)
        print(f"üé¨ –í–∏–¥–µ–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ –∞—É–¥–∏–æ: {output_video}")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –≤–∏–¥–µ–æ: {e}")

def process_user_input():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –≤–≤–æ–¥–∞ –∏ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–¥–µ–æ–æ—Ç–≤–µ—Ç–∞.
    """

    # === –®–∞–≥ 1: –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ ===
    audio_file = os.path.join(GREETINGS_TEMP, "user_input.wav")
    record_audio(audio_file)

    # === –®–∞–≥ 2: –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏ ===
    start_time = time.time()  # –ù–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏
    print("[STT] –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏...")
    user_text = transcribe_wav_to_text(audio_file)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
    stt_end_time = time.time()  # –ö–æ–Ω–µ—Ü –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è STT
    print(f"[STT] –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç: {user_text}")

    # === –®–∞–≥ 3: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–æ–º–æ—â—å—é YandexGPT ===
    ai_start_time = time.time()  # –ù–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è AI
    print("[AI] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
    response_text = generate_text(user_text)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º YandexGPT
    ai_end_time = time.time()  # –ö–æ–Ω–µ—Ü –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è AI
    print(f"[AI] –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç: {response_text}")
    print(f"[‚è±Ô∏è] –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: {ai_end_time - ai_start_time:.2f} —Å–µ–∫—É–Ω–¥")

    # === –®–∞–≥ 4: –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ ===
    tts_start_time = time.time()  # –ù–∞—á–∞–ª–æ –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è TTS
    print("[TTS] –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏...")
    session_id = os.urandom(4).hex()
    audio_path = os.path.join(GREETINGS_TEMP, f"response_audio_{session_id}.ogg")
    audio_bytes = text_to_audio(response_text, voice="zahar")  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ–ª–æ—Å "zahar"
    with open(audio_path, "wb") as f:
        f.write(audio_bytes)
    tts_end_time = time.time()  # –ö–æ–Ω–µ—Ü –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è TTS
    print(f"[TTS] –ê—É–¥–∏–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {audio_path}")
    print(f"[‚è±Ô∏è] –í—Ä–µ–º—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {tts_end_time - tts_start_time:.2f} —Å–µ–∫—É–Ω–¥")

    # === –®–∞–≥ 5: –ü–æ–∏—Å–∫ —à–∞–±–ª–æ–Ω–∞ –≤–∏–¥–µ–æ ===
    template_videos = [f for f in os.listdir(GREETINGS_TEMP) if f.endswith(".webm")]
    if not template_videos:
        raise FileNotFoundError(f"–®–∞–±–ª–æ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ø–∞–ø–∫–µ: {GREETINGS_TEMP}")

    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —à–∞–±–ª–æ–Ω
    template_video_name = template_videos[0]
    template_video = os.path.join(GREETINGS_TEMP, template_video_name)
    print(f"[VIDEO] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —à–∞–±–ª–æ–Ω–Ω–æ–µ –≤–∏–¥–µ–æ: {template_video}")

    # === –®–∞–≥ 6: –ê–¥–∞–ø—Ç–∞—Ü–∏—è –≤–∏–¥–µ–æ –ø–æ–¥ –Ω–æ–≤—É—é –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫—É ===
    adjusted_video = os.path.join(GREETINGS_TEMP, f"adjusted_video_{session_id}.webm")
    adjust_video_duration(template_video, audio_path, adjusted_video)

    # === –®–∞–≥ 7: –ó–∞–º–µ–Ω–∞ –∞—É–¥–∏–æ–¥–æ—Ä–æ–∂–∫–∏ ===
    output_video = os.path.join(TEMP_INFERENCE, f"final_response_{session_id}.webm")
    replace_audio_in_video(adjusted_video, audio_path, output_video)

    # === –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ===
    end_time = time.time()  # –ö–æ–Ω–µ—Ü –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏
    total_time = end_time - start_time
    print(f"[‚è±Ô∏è] –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")

    return output_video

if __name__ == "__main__":
    try:
        video_path = process_user_input()
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ò—Ç–æ–≥–æ–≤–æ–µ –≤–∏–¥–µ–æ: {video_path}")
    except Exception as e:
        print(f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")