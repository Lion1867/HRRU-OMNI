'''import os
import sys
import tempfile
import shutil  # –¥–ª—è –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
import pytest
from pydub import AudioSegment
import librosa
import torch

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ interview_module
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'interview_module')))
from Yandex_TTS1 import text_to_audio


@pytest.fixture
def temp_dir():
    with tempfile.TemporaryDirectory() as tmpdir:
        yield tmpdir


def test_text_to_audio_returns_bytes():
    audio = text_to_audio("–ü—Ä–∏–≤–µ—Ç, –¥–æ—Ä–æ–≥–∏–µ –∫–æ–ª–ª–µ–≥–∏, —Å –Ω–∞—Å—Ç—É–ø–∞—é—â–∏–º, –¥—Ä—É–∑—å—è!", "oksana")
    assert isinstance(audio, bytes) and len(audio) > 0


def test_text_to_audio_generates_valid_ogg():
    audio = text_to_audio("–ü—Ä–∏–≤–µ—Ç, –¥–æ—Ä–æ–≥–∏–µ –∫–æ–ª–ª–µ–≥–∏, —Å –Ω–∞—Å—Ç—É–ø–∞—é—â–∏–º, –¥—Ä—É–∑—å—è!", "oksana")
    assert audio.startswith(b"OggS"), "–ê—É–¥–∏–æ –Ω–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ Ogg Opus"


def test_utmos_score_for_tts_audio(temp_dir):
    """–¢–µ—Å—Ç –∫–∞—á–µ—Å—Ç–≤–∞ TTS —á–µ—Ä–µ–∑ UTMOS22 (SpeechMOS) ‚Äî –±–µ–∑ fairseq!"""
    text = "–ü—Ä–∏–≤–µ—Ç, –¥–æ—Ä–æ–≥–∏–µ –∫–æ–ª–ª–µ–≥–∏, —Å –Ω–∞—Å—Ç—É–ø–∞—é—â–∏–º, –¥—Ä—É–∑—å—è!"
    voice = "oksana"

    # 1. –ü–æ–ª—É—á–∞–µ–º –∞—É–¥–∏–æ –æ—Ç Yandex TTS
    audio_bytes = text_to_audio(text, voice)
    ogg_path = os.path.join(temp_dir, "speech.ogg")
    with open(ogg_path, "wb") as f:
        f.write(audio_bytes)

    # 2. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º Ogg Opus ‚Üí 16kHz mono WAV
    wav_path = os.path.join(temp_dir, "speech.wav")
    audio = AudioSegment.from_ogg(ogg_path)
    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
    audio.export(wav_path, format="wav")

    assert os.path.exists(wav_path) and os.path.getsize(wav_path) > 0

    # 3. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è
    SAVE_AUDIO_FOR_LISTENING = os.getenv("SAVE_TTS_AUDIO", "0") == "1"
    if SAVE_AUDIO_FOR_LISTENING:
        # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö –∞—É–¥–∏–æ —Ä—è–¥–æ–º —Å —Ç–µ—Å—Ç–æ–º
        output_dir = os.path.join(os.path.dirname(__file__), "saved_audio")
        os.makedirs(output_dir, exist_ok=True)
        saved_wav = os.path.join(output_dir, "latest_tts_output.wav")
        shutil.copy2(wav_path, saved_wav)
        print(f"\nüîä –ê—É–¥–∏–æ—Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è: {saved_wav}")

    # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º UTMOS22 —á–µ—Ä–µ–∑ torch.hub
    predictor = torch.hub.load("tarepan/SpeechMOS:v1.2.0", "utmos22_strong", trust_repo=True)

    # 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ –∏ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º MOS
    wave, sr = librosa.load(wav_path, sr=None, mono=True)
    with torch.no_grad():
        score_tensor = predictor(torch.from_numpy(wave).unsqueeze(0), sr)
    mos_pred = score_tensor.item()

    print(f"\n[UTMOS22] Predicted MOS: {mos_pred:.3f}")

    # 6. –ü—Ä–æ–≤–µ—Ä–∫–∏
    assert 1.0 <= mos_pred <= 5.0, f"MOS –≤—ã—à–µ–ª –∑–∞ –¥–æ–ø—É—Å—Ç–∏–º—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã: {mos_pred:.3f}"
    assert mos_pred > 3.0, f"MOS —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∏–π: {mos_pred:.3f}"'''



'''import torch
import librosa

# –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞ (–¥–æ–ª–∂–µ–Ω –±—ã—Ç—å WAV, –∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ 16 –∫–ì—Ü, –º–æ–Ω–æ ‚Äî librosa —Å–∞–º–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç)
wave, sr = librosa.load("temp_16k_mono.wav", sr=None, mono=True)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ UTMOS —á–µ—Ä–µ–∑ torch.hub
predictor = torch.hub.load("tarepan/SpeechMOS:v1.2.0", "utmos22_strong", trust_repo=True)

# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ MOS (–≤–∞–∂–Ω–æ: –¥–æ–±–∞–≤–∏—Ç—å batch dimension —á–µ—Ä–µ–∑ unsqueeze(0))
with torch.no_grad():
    score = predictor(torch.from_numpy(wave).unsqueeze(0), sr)

# –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
mos_value = score.item()
print(f"üéôÔ∏è UTMOS (SpeechMOS): {mos_value:.3f}")'''


'''
import os
import sys
import tempfile
import pandas as pd
import numpy as np
import torch
import librosa
from pydub import AudioSegment
import time
import random
from datetime import datetime

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'interview_module')))
from Yandex_TTS1 import text_to_audio

def load_transcript(file_path, max_samples=None):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞ transcript.txt"""
    texts = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('|')
                if len(parts) >= 3:
                    text = parts[1].strip()
                    if text:
                        texts.append(text)
        
        if max_samples and len(texts) > max_samples:
            texts = texts[:max_samples]
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ {file_path}")
        return texts
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return []

def evaluate_tts_on_transcript(transcript_file, num_samples=50, save_samples=10):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏"""
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç—ã
    texts = load_transcript(transcript_file, num_samples)
    if not texts:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç—ã")
        return
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å MOS
    print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ MOS...")
    mos_predictor = torch.hub.load("tarepan/SpeechMOS:v1.2.0", "utmos22_strong", trust_repo=True)
    mos_predictor.eval()
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–ª–æ—Å–∞ 50/50
    voices = ["oksana", "zahar"]
    voice_assignment = []
    for i in range(len(texts)):
        voice_assignment.append(voices[0] if i < len(texts) // 2 else voices[1])
    random.shuffle(voice_assignment)
    
    print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {voice_assignment.count(voices[0])}x {voices[0]}, "
          f"{voice_assignment.count(voices[1])}x {voices[1]}")
    
    results = []
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ
    if save_samples > 0:
        os.makedirs("results\\tts_samples", exist_ok=True)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
    for i, (text, voice) in enumerate(zip(texts, voice_assignment)):
        try:
            print(f"\n[{i+1}/{len(texts)}] {voice}: {text[:50]}...")
            
            # –°–∏–Ω—Ç–µ–∑
            audio_bytes = text_to_audio(text, voice)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as f:
                f.write(audio_bytes)
                ogg_path = f.name
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV
            wav_path = ogg_path.replace('.ogg', '.wav')
            audio = AudioSegment.from_ogg(ogg_path)
            audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
            audio.export(wav_path, format="wav")
            
            # –û—Ü–µ–Ω–∫–∞ MOS
            wave, sr = librosa.load(wav_path, sr=16000, mono=True)
            with torch.no_grad():
                mos_score = mos_predictor(torch.from_numpy(wave).unsqueeze(0), sr)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            saved_path = None
            if i < save_samples:
                timestamp = datetime.now().strftime("%H%M%S")
                save_path = f"results\\tts_samples\\{voice}_{i:03d}_{timestamp}.wav"
                import shutil
                shutil.copy2(wav_path, save_path)
                saved_path = save_path
            
            results.append({
                "text": text,
                "voice": voice,
                "mos_score": mos_score.item(),
                "sample_id": i,
                "audio_path": saved_path
            })
            
            print(f"  MOS: {mos_score.item():.3f}")
            
            # –û—á–∏—Å—Ç–∫–∞
            os.unlink(ogg_path)
            os.unlink(wav_path)
            
            time.sleep(0.3)
            
        except Exception as e:
            print(f"  –û—à–∏–±–∫–∞: {e}")
            continue
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if results:
        df = pd.DataFrame(results)
        
        print("\n" + "="*50)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print("="*50)
        
        for voice in voices:
            voice_df = df[df["voice"] == voice]
            if len(voice_df) > 0:
                scores = voice_df["mos_score"]
                print(f"\n{voice.upper()}: {len(voice_df)} –ø—Ä–∏–º–µ—Ä–æ–≤")
                print(f"  –°—Ä–µ–¥–Ω–∏–π: {scores.mean():.3f}")
                print(f"  –õ—É—á—à–∏–π: {scores.max():.3f}")
                print(f"  –•—É–¥—à–∏–π: {scores.min():.3f}")
        
        print(f"\n–û–ë–©–ò–ô –°–†–ï–î–ù–ò–ô: {df['mos_score'].mean():.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        df.to_csv(f"results\\tts_results_{timestamp}.csv", index=False, encoding='utf-8')
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ tts_results_{timestamp}.csv")

if __name__ == "__main__":
    transcript_file = os.path.join("data", "speech_dataset", "ru", "transcript.txt")
    
    evaluate_tts_on_transcript(transcript_file, num_samples=50, save_samples=15)'''

import os
import sys
import tempfile
import pandas as pd
import numpy as np
import torch
import librosa
from pydub import AudioSegment
import time
import random
from datetime import datetime
import argparse

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', 'interview_module')))
from Yandex_TTS1 import text_to_audio

def load_transcript(file_path, max_samples=None):
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–µ–∫—Å—Ç—ã –∏–∑ —Ñ–∞–π–ª–∞ transcript.txt"""
    texts = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                parts = line.strip().split('|')
                if len(parts) >= 3:
                    text = parts[1].strip()
                    if text:
                        texts.append(text)
        
        if max_samples and len(texts) > max_samples:
            texts = texts[:max_samples]
        
        print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(texts)} —Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ {file_path}")
        return texts
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Ñ–∞–π–ª–∞: {e}")
        return []

def evaluate_tts_on_transcript(transcript_file, num_samples=50, save_samples=10, 
                               voices=None, model_name="utmos22_strong", 
                               sleep_time=0.3, output_dir="results"):
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ—Ü–µ–Ω–∫–∏ TTS
    
    Args:
        transcript_file: –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞–º–∏
        num_samples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏
        save_samples: –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        voices: —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ—Å–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        model_name: –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ MOS
        sleep_time: –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ (—Å–µ–∫—É–Ω–¥—ã)
        output_dir: –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
    if voices is None:
        voices = ["oksana", "zahar"]
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    tts_samples_dir = os.path.join(output_dir, "tts_samples")
    os.makedirs(tts_samples_dir, exist_ok=True)
    os.makedirs(output_dir, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç—ã
    texts = load_transcript(transcript_file, num_samples)
    if not texts:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ–∫—Å—Ç—ã")
        return None
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å MOS
    print(f"–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ MOS ({model_name})...")
    try:
        mos_predictor = torch.hub.load("tarepan/SpeechMOS:v1.2.0", model_name, trust_repo=True)
        mos_predictor.eval()
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ MOS: {e}")
        print("–ü—Ä–æ–±—É—é –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å skip_validation...")
        mos_predictor = torch.hub.load("tarepan/SpeechMOS:v1.2.0", model_name, 
                                      trust_repo=True, skip_validation=True)
        mos_predictor.eval()
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ–ª–æ—Å–∞
    voice_assignment = []
    half_samples = len(texts) // 2
    
    # –ü–µ—Ä–≤–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ - –ø–µ—Ä–≤—ã–π –≥–æ–ª–æ—Å
    for i in range(half_samples):
        voice_assignment.append(voices[0])
    
    # –í—Ç–æ—Ä–∞—è –ø–æ–ª–æ–≤–∏–Ω–∞ - –≤—Ç–æ—Ä–æ–π –≥–æ–ª–æ—Å
    for i in range(len(texts) - half_samples):
        voice_assignment.append(voices[1])
    
    # –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º
    random.shuffle(voice_assignment)
    
    print(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤: {voice_assignment.count(voices[0])}x {voices[0]}, "
          f"{voice_assignment.count(voices[1])}x {voices[1]}")
    
    results = []
    successful_count = 0
    failed_count = 0
    
    print(f"\n–ù–∞—á–∏–Ω–∞—é –æ—Ü–µ–Ω–∫—É {len(texts)} –ø—Ä–∏–º–µ—Ä–æ–≤...")
    print("="*60)
    
    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤
    for i, (text, voice) in enumerate(zip(texts, voice_assignment)):
        try:
            print(f"\n[{i+1}/{len(texts)}] {voice}: {text[:50]}...")
            
            # –°–∏–Ω—Ç–µ–∑
            audio_bytes = text_to_audio(text, voice)
            
            if not audio_bytes or len(audio_bytes) == 0:
                print("  –û—à–∏–±–∫–∞: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç TTS")
                failed_count += 1
                continue
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
            with tempfile.NamedTemporaryFile(suffix='.ogg', delete=False) as f:
                f.write(audio_bytes)
                ogg_path = f.name
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ WAV
            wav_path = ogg_path.replace('.ogg', '.wav')
            try:
                audio = AudioSegment.from_ogg(ogg_path)
                audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)
                audio.export(wav_path, format="wav")
            except Exception as e:
                print(f"  –û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ –∞—É–¥–∏–æ: {e}")
                os.unlink(ogg_path)
                failed_count += 1
                continue
            
            # –û—Ü–µ–Ω–∫–∞ MOS
            try:
                wave, sr = librosa.load(wav_path, sr=16000, mono=True)
                with torch.no_grad():
                    mos_score = mos_predictor(torch.from_numpy(wave).unsqueeze(0), sr)
            except Exception as e:
                print(f"  –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ MOS: {e}")
                mos_score = torch.tensor([0.0])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            saved_path = None
            if i < save_samples:
                timestamp = datetime.now().strftime("%H%M%S")
                save_path = os.path.join(tts_samples_dir, f"{voice}_{i:03d}_{timestamp}.wav")
                import shutil
                try:
                    shutil.copy2(wav_path, save_path)
                    saved_path = save_path
                except Exception as e:
                    print(f"  –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—É–¥–∏–æ: {e}")
            
            results.append({
                "text": text,
                "voice": voice,
                "mos_score": mos_score.item(),
                "sample_id": i,
                "audio_path": saved_path,
                "text_length": len(text),
                "timestamp": datetime.now().isoformat()
            })
            
            successful_count += 1
            print(f"  MOS: {mos_score.item():.3f}")
            
            # –û—á–∏—Å—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
            if os.path.exists(ogg_path):
                os.unlink(ogg_path)
            if os.path.exists(wav_path):
                os.unlink(wav_path)
            
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
            time.sleep(sleep_time)
            
        except Exception as e:
            print(f"  –û—à–∏–±–∫–∞: {e}")
            import traceback
            traceback.print_exc()
            failed_count += 1
            continue
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if results:
        df = pd.DataFrame(results)
        
        print("\n" + "="*60)
        print("–†–ï–ó–£–õ–¨–¢–ê–¢–´ –û–¶–ï–ù–ö–ò TTS")
        print("="*60)
        
        print(f"\n–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
        print(f"  –í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(texts)}")
        print(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful_count}")
        print(f"  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å: {failed_count}")
        print(f"  –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {successful_count/len(texts)*100:.1f}%")
        
        for voice in voices:
            voice_df = df[df["voice"] == voice]
            if len(voice_df) > 0:
                scores = voice_df["mos_score"]
                print(f"\n–ì–æ–ª–æ—Å: {voice.upper()}")
                print(f"  –ü—Ä–∏–º–µ—Ä–æ–≤: {len(voice_df)}")
                print(f"  –°—Ä–µ–¥–Ω–∏–π MOS: {scores.mean():.3f}")
                print(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {scores.std():.3f}")
                print(f"  –õ—É—á—à–∏–π: {scores.max():.3f}")
                print(f"  –•—É–¥—à–∏–π: {scores.min():.3f}")
                print(f"  –ú–µ–¥–∏–∞–Ω–∞: {scores.median():.3f}")
        
        print(f"\n–û–ë–©–ò–ô –°–†–ï–î–ù–ò–ô MOS: {df['mos_score'].mean():.3f}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞
        if 'text_length' in df.columns:
            print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥–ª–∏–Ω–µ —Ç–µ–∫—Å—Ç–∞:")
            print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞: {df['text_length'].mean():.1f} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"  –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {df['text_length'].min()} —Å–∏–º–≤–æ–ª–æ–≤")
            print(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞: {df['text_length'].max()} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –º–µ–∂–¥—É –¥–ª–∏–Ω–æ–π —Ç–µ–∫—Å—Ç–∞ –∏ MOS
            correlation = df['text_length'].corr(df['mos_score'])
            print(f"  –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –¥–ª–∏–Ω–∞-MOS: {correlation:.3f}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # CSV —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        csv_filename = os.path.join(output_dir, f"tts_results_{timestamp}.csv")
        df.to_csv(csv_filename, index=False, encoding='utf-8')
        print(f"\n–ü–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {csv_filename}")
        
        # TXT —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π
        stats_filename = os.path.join(output_dir, f"tts_stats_{timestamp}.txt")
        with open(stats_filename, 'w', encoding='utf-8') as f:
            f.write("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–¶–ï–ù–ö–ò TTS –ö–ê–ß–ï–°–¢–í–ê\n")
            f.write("="*60 + "\n")
            f.write(f"–î–∞—Ç–∞ –æ—Ü–µ–Ω–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤: {transcript_file}\n")
            f.write(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {len(texts)}\n")
            f.write(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful_count}\n")
            f.write(f"–ì–æ–ª–æ—Å–∞: {', '.join(voices)}\n")
            f.write(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: 50% {voices[0]}, 50% {voices[1]}\n")
            f.write(f"–ú–æ–¥–µ–ª—å MOS: {model_name}\n\n")
            
            for voice in voices:
                voice_df = df[df["voice"] == voice]
                if len(voice_df) > 0:
                    scores = voice_df["mos_score"]
                    f.write(f"–ì–û–õ–û–°: {voice.upper()}\n")
                    f.write(f"  –ü—Ä–∏–º–µ—Ä–æ–≤: {len(voice_df)}\n")
                    f.write(f"  –°—Ä–µ–¥–Ω–∏–π MOS: {scores.mean():.3f}\n")
                    f.write(f"  –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {scores.std():.3f}\n")
                    f.write(f"  –ú–∏–Ω–∏–º—É–º: {scores.min():.3f}\n")
                    f.write(f"  –ú–∞–∫—Å–∏–º—É–º: {scores.max():.3f}\n")
                    f.write(f"  –ú–µ–¥–∏–∞–Ω–∞: {scores.median():.3f}\n\n")
            
            f.write(f"–û–ë–©–ò–ô –°–†–ï–î–ù–ò–ô: {df['mos_score'].mean():.3f}\n")
        
        print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {stats_filename}")
        
        # README —Ñ–∞–π–ª
        readme_filename = os.path.join(output_dir, f"README_{timestamp}.txt")
        with open(readme_filename, 'w', encoding='utf-8') as f:
            f.write("–û–ü–ò–°–ê–ù–ò–ï –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê\n")
            f.write("="*60 + "\n")
            f.write("–¶–µ–ª—å: –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏ (TTS) —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫–∏ MOS\n")
            f.write("TTS —Å–∏—Å—Ç–µ–º–∞: Yandex SpeechKit\n")
            f.write(f"–ú–æ–¥–µ–ª—å MOS: {model_name}\n")
            f.write(f"–§–∞–π–ª —Å —Ç–µ–∫—Å—Ç–∞–º–∏: {os.path.basename(transcript_file)}\n")
            f.write(f"–ì–æ–ª–æ—Å–∞: {', '.join(voices)}\n")
            f.write("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: 50% –Ω–∞ –∫–∞–∂–¥—ã–π –≥–æ–ª–æ—Å\n")
            f.write(f"\n–°–æ–∑–¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã:\n")
            f.write(f"1. {os.path.basename(csv_filename)} - –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n")
            f.write(f"2. {os.path.basename(stats_filename)} - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞\n")
            f.write(f"3. –ü–∞–ø–∫–∞ 'tts_samples' - –ø—Ä–∏–º–µ—Ä—ã —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ\n")
        
        print(f"–û–ø–∏—Å–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {readme_filename}")
        
        return df
    else:
        print("\n–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return None

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Å CLI –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–º"""
    parser = argparse.ArgumentParser(
        description='–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ TTS —Å –ø–æ–º–æ—â—å—é –º–µ—Ç—Ä–∏–∫–∏ MOS',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python tts_evaluator.py                    # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (10 –ø—Ä–∏–º–µ—Ä–æ–≤)
  python tts_evaluator.py -n 50              # 50 –ø—Ä–∏–º–µ—Ä–æ–≤
  python tts_evaluator.py -n 100 -s 20       # 100 –ø—Ä–∏–º–µ—Ä–æ–≤, —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å 20 –∞—É–¥–∏–æ
  python tts_evaluator.py -v oksana alena    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å–∞ oksana –∏ alena
  python tts_evaluator.py -t custom.txt      # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–π —Ñ–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
  python tts_evaluator.py -m utmos22_weak    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥—É—é –º–æ–¥–µ–ª—å MOS
  python tts_evaluator.py --sleep 0.5        # –ü–∞—É–∑–∞ 0.5 —Å–µ–∫ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é:
  –§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤: data/speech_dataset/ru/transcript.txt
  –ì–æ–ª–æ—Å–∞: oksana, zahar (50/50 —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
  –ú–æ–¥–µ–ª—å MOS: utmos22_strong
        """
    )
    
    # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    parser.add_argument('-t', '--transcript', type=str, 
                       default=os.path.join("data", "speech_dataset", "ru", "transcript.txt"),
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É transcript.txt')
    parser.add_argument('-n', '--num_samples', type=int, default=10,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –¥–ª—è –æ—Ü–µ–Ω–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 10)')
    parser.add_argument('-s', '--save_samples', type=int, default=5,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 5)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–æ–ª–æ—Å–æ–≤
    parser.add_argument('-v', '--voices', nargs=2, default=['oksana', 'zahar'],
                       help='–î–≤–∞ –≥–æ–ª–æ—Å–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: oksana zahar)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    parser.add_argument('-m', '--model', type=str, default='utmos22_strong',
                       choices=['utmos22_strong', 'utmos22_weak', 'uTMOS'],
                       help='–ú–æ–¥–µ–ª—å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ MOS (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: utmos22_strong)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    parser.add_argument('--sleep', type=float, default=0.3,
                       help='–ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏ TTS –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0.3)')
    
    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–≤–æ–¥–∞
    parser.add_argument('-o', '--output', type=str, default='results',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: results)')
    
    # –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç
    parser.add_argument('--quick', action='store_true',
                       help='–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç (5 –ø—Ä–∏–º–µ—Ä–æ–≤, 2 –∞—É–¥–∏–æ)')
    
    # –ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥
    parser.add_argument('--verbose', action='store_true',
                       help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥ –ø—Ä–æ—Ü–µ—Å—Å–∞')
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤
    if not os.path.exists(args.transcript):
        print(f"–û—à–∏–±–∫–∞: —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.transcript}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ –¥—Ä—É–≥–æ–π —Ñ–∞–π–ª —Å –ø–æ–º–æ—â—å—é -t")
        return
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
    if args.quick:
        args.num_samples = 5
        args.save_samples = 2
        args.sleep = 0.2
        print("–†–µ–∂–∏–º –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞: 5 –ø—Ä–∏–º–µ—Ä–æ–≤, 2 –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞")
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –∑–∞–ø—É—Å–∫–µ
    print("="*60)
    print("–û–¶–ï–ù–ö–ê –ö–ê–ß–ï–°–¢–í–ê TTS (–°–ò–ù–¢–ï–ó –†–ï–ß–ò)")
    print("="*60)
    print(f"–§–∞–π–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–æ–≤: {args.transcript}")
    print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤: {args.num_samples}")
    print(f"–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –∞—É–¥–∏–æ: {args.save_samples}")
    print(f"–ì–æ–ª–æ—Å–∞: {args.voices[0]} –∏ {args.voices[1]} (50/50 —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)")
    print(f"–ú–æ–¥–µ–ª—å MOS: {args.model}")
    print(f"–ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏: {args.sleep} —Å–µ–∫")
    print(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {args.output}")
    print("="*60)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Ü–µ–Ω–∫—É
    try:
        results = evaluate_tts_on_transcript(
            transcript_file=args.transcript,
            num_samples=args.num_samples,
            save_samples=args.save_samples,
            voices=args.voices,
            model_name=args.model,
            sleep_time=args.sleep,
            output_dir=args.output
        )
        
        if results is not None:
            print("\n" + "="*60)
            print("–û–¶–ï–ù–ö–ê –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
            print("="*60)
            print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ: {args.output}")
            print("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ:")
            print(f"  1. tts_results_*.csv - –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
            print(f"  2. tts_stats_*.txt - —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
            print(f"  3. README_*.txt - –æ–ø–∏—Å–∞–Ω–∏–µ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞")
            print(f"  4. tts_samples/ - –ø—Ä–∏–º–µ—Ä—ã —Å–∏–Ω—Ç–µ–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞—É–¥–∏–æ")
        
        return results
        
    except KeyboardInterrupt:
        print("\n\n–û—Ü–µ–Ω–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"\n–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    random.seed(42)
    np.random.seed(42)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å CLI
    main()