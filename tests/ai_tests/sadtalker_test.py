'''import os
import sys
import subprocess
import argparse
import glob
import warnings
import librosa
import numpy as np
import pandas as pd
from datetime import datetime
import cv2
from scipy.interpolate import interp1d
from sklearn.metrics.pairwise import cosine_similarity

warnings.filterwarnings('ignore')

# === –ê—Ä–≥—É–º–µ–Ω—Ç—ã ===
parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ª–∏–ø—Å–∏–Ω–∫–∞ —á–µ—Ä–µ–∑ SadTalker + –æ—Ü–µ–Ω–∫–∞ LSE-D")
parser.add_argument("--image_path", type=str, required=True, help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –ª–∏—Ü–∞")
parser.add_argument("--driven_audio", type=str, required=True, help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (.wav, 16kHz, mono)")
parser.add_argument("--result_dir", type=str, default="TEMP_VIDEO", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ")
args = parser.parse_args()

SOURCE_IMAGE_PATH = args.image_path
AUDIO_PATH = args.driven_audio
RESULT_DIR = args.result_dir

# === –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ===
os.makedirs(RESULT_DIR, exist_ok=True)

# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã SadTalker ===
POSE_STYLE = 0
BATCH_SIZE = 2
SIZE = 256
EXPRESSION_SCALE = 1.0
PREPROCESS = 'full'
STILL_MODE = True
CHECKPOINT_DIR = 'SadTalker/checkpoints'
VENV_PATH = 'SadTalker/venv/Scripts/activate.bat'

# === –ó–∞–ø—É—Å–∫ SadTalker ===
def run_sadtalker(image_path, audio_path, result_dir):
    still_flag = "--still" if STILL_MODE else ""
    command = (
        f'"{VENV_PATH}" && python SadTalker/inference.py '
        f'--driven_audio "{audio_path}" '
        f'--source_image "{image_path}" '
        f'--checkpoint_dir "{CHECKPOINT_DIR}" '
        f'--result_dir "{result_dir}" '
        f'--pose_style {POSE_STYLE} '
        f'--batch_size {BATCH_SIZE} '
        f'--size {SIZE} '
        f'--expression_scale {EXPRESSION_SCALE} '
        f'--preprocess {PREPROCESS} '
        f'{still_flag}'
    )
    print("–ó–∞–ø—É—Å–∫ SadTalker...")
    try:
        subprocess.run(command, shell=True, check=True)
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ SadTalker: {e}")
        sys.exit(1)

# === –ü–æ–∏—Å–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –≤–∏–¥–µ–æ ===
def find_generated_video(result_dir, image_path, audio_path):
    image_base = os.path.splitext(os.path.basename(image_path))[0]
    audio_base = os.path.splitext(os.path.basename(audio_path))[0]
    expected_name = f"{image_base}#{audio_base}.mp4"
    candidate = os.path.join(result_dir, expected_name)
    if os.path.isfile(candidate):
        return candidate
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –∏—â–µ–º –ª—é–±–æ–π .mp4
    mp4_files = glob.glob(os.path.join(result_dir, "*.mp4"))
    if mp4_files:
        return mp4_files[0]
    raise FileNotFoundError(f"–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –≤ {result_dir}")

# === LSE-D: Lip Sync Error (Distance) ===
def compute_lse_d(video_path: str, audio_path: str) -> float:
    try:
        # –ê—É–¥–∏–æ: MFCC –∫–∞–∫ –ø—Ä–∏–±–ª–∏–∂–µ–Ω–∏–µ —Ñ–æ–Ω–µ–º
        audio, sr = librosa.load(audio_path, sr=16000, mono=True)
        mfcc = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=13)
        audio_features = mfcc.T  # (time, 13)

        # –í–∏–¥–µ–æ: –∏–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –≥—É–± (–ø—Ä–æ—Å—Ç–æ —Ä–µ—Å–∞–π–∑–∏–º –≤—Å—ë –ª–∏—Ü–æ ‚Äî –∫–∞–∫ proxy)
        cap = cv2.VideoCapture(video_path)
        lip_frames = []
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            small = cv2.resize(frame, (96, 96))
            lip_frames.append(small.flatten())
        cap.release()

        if not lip_frames:
            raise ValueError("–í–∏–¥–µ–æ –ø—É—Å—Ç–æ–µ")

        lip_features = np.array(lip_frames)  # (N, 96*96*3)

        # –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —á–µ—Ä–µ–∑ –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—é
        x_old = np.linspace(0, 1, len(lip_features))
        x_new = np.linspace(0, 1, len(audio_features))
        lip_interp = interp1d(x_old, lip_features, axis=0, fill_value="extrapolate")(x_new)

        # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
        min_len = min(lip_interp.shape[0], audio_features.shape[0])
        lip_part = lip_interp[:min_len]
        audio_part = audio_features[:min_len]

        lip_norm = lip_part / (np.linalg.norm(lip_part, axis=1, keepdims=True) + 1e-8)
        audio_norm = audio_part / (np.linalg.norm(audio_part, axis=1, keepdims=True) + 1e-8)

        cos_sim = cosine_similarity(lip_norm, audio_norm).diagonal()
        lse_d = 1.0 - np.mean(cos_sim)
        return float(lse_d)

    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ LSE-D: {e}")
        return float('inf')

# === –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ ===
if __name__ == "__main__":
    print("=" * 60)
    print("–¢–ï–°–¢ SADTALKER + LSE-D –û–¶–ï–ù–ö–ê")
    print("=" * 60)

    # –ó–∞–ø—É—Å–∫–∞–µ–º –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
    run_sadtalker(SOURCE_IMAGE_PATH, AUDIO_PATH, RESULT_DIR)

    # –ù–∞—Ö–æ–¥–∏–º –≤–∏–¥–µ–æ
    try:
        video_file = find_generated_video(RESULT_DIR, SOURCE_IMAGE_PATH, AUDIO_PATH)
        print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ: {video_file}")
    except FileNotFoundError as e:
        print(e)
        print("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–∞–ø–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤:")
        for f in os.listdir(RESULT_DIR):
            print(f"  - {f}")
        sys.exit(1)

    # –°—á–∏—Ç–∞–µ–º LSE-D
    print("\n–í—ã—á–∏—Å–ª–µ–Ω–∏–µ LSE-D...")
    lse_score = compute_lse_d(video_file, AUDIO_PATH)
    print(f"\nüìä LSE-D –°–∫–æ—Ä: {lse_score:.4f}")
    print("  ‚Ä¢ –ú–µ–Ω—å—à–µ = –ª—É—á—à–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è")
    print("  ‚Ä¢ –•–æ—Ä–æ—à–æ: < 0.3, –ü–ª–æ—Ö–æ: > 0.5")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    results = pd.DataFrame([{
        'image_path': SOURCE_IMAGE_PATH,
        'audio_path': AUDIO_PATH,
        'video_path': video_file,
        'lse_d': lse_score,
        'timestamp': datetime.now().isoformat()
    }])
    results.to_csv("sadtalker_lse_results.csv", index=False, encoding='utf-8')
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: sadtalker_lse_results.csv")'''

import torch
torch.cuda.is_available = lambda: False  # Force CPU

import os
import sys
import subprocess
import argparse
import glob
import warnings
import pandas as pd
from datetime import datetime
import urllib.request
import shutil

warnings.filterwarnings('ignore')

# === –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ syncnet-python (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ===
try:
    from syncnet_python import SyncNetPipeline
except ImportError:
    print("–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ 'syncnet-python' –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ—ë: pip install syncnet-python")
    print("–¢–∞–∫–∂–µ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω ffmpeg.")
    sys.exit(1)

# === –ê—Ä–≥—É–º–µ–Ω—Ç—ã ===
parser = argparse.ArgumentParser(description="–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ª–∏–ø—Å–∏–Ω–∫–∞ —á–µ—Ä–µ–∑ SadTalker + –æ—Ü–µ–Ω–∫–∞ LSE-D —á–µ—Ä–µ–∑ SyncNet")
parser.add_argument("--image_path", type=str, required=True, help="–ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –ª–∏—Ü–∞")
parser.add_argument("--driven_audio", type=str, required=True, help="–ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É (.wav, 16kHz, mono)")
parser.add_argument("--result_dir", type=str, default="TEMP_VIDEO", help="–ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∏–¥–µ–æ")
args = parser.parse_args()

SOURCE_IMAGE_PATH = args.image_path
AUDIO_PATH = args.driven_audio
RESULT_DIR = args.result_dir

# === –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ ===
os.makedirs(RESULT_DIR, exist_ok=True)

# === –í–µ—Å–∞ SyncNet ===
WEIGHTS_DIR = "syncnet_weights"
os.makedirs(WEIGHTS_DIR, exist_ok=True)

SFD_WEIGHTS = os.path.join(WEIGHTS_DIR, "sfd_face.pth")
SYNCNET_WEIGHTS = os.path.join(WEIGHTS_DIR, "syncnet_v2.model")

def download_file(url, dest):
    if os.path.exists(dest):
        print(f"{os.path.basename(dest)} —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
        return
    print(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {os.path.basename(dest)}...")
    try:
        import urllib.request
        req = urllib.request.Request(url)
        req.add_header('User-Agent', 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
        with urllib.request.urlopen(req) as response, open(dest, 'wb') as out_file:
            total_size = response.getheader('Content-Length')
            if total_size is None:
                out_file.write(response.read())
            else:
                total_size = int(total_size)
                downloaded = 0
                chunk_size = 8192
                while True:
                    chunk = response.read(chunk_size)
                    if not chunk:
                        break
                    out_file.write(chunk)
                    downloaded += len(chunk)
        print(f"{os.path.basename(dest)} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω.")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è: {e}")
        if os.path.exists(dest):
            os.remove(dest)
        raise
'''
# –°–∫–∞—á–∏–≤–∞–µ–º –≤–µ—Å–∞
download_file(
    "http://www.robots.ox.ac.uk/~vgg/software/lipsync/data/syncnet_v2.model",
    SYNCNET_WEIGHTS
)
download_file(
    "http://www.robots.ox.ac.uk/~vgg/software/lipsync/data/sfd_face.pth",
    SFD_WEIGHTS
)
'''
# === –ü–∞—Ä–∞–º–µ—Ç—Ä—ã SadTalker ===
POSE_STYLE = 0
BATCH_SIZE = 2
SIZE = 256
EXPRESSION_SCALE = 1.0
PREPROCESS = 'full'
STILL_MODE = True
CHECKPOINT_DIR = 'SadTalker/checkpoints'
VENV_PATH = 'SadTalker/venv/Scripts/activate.bat'

def run_sadtalker(image_path, audio_path, result_dir):
    still_flag = "--still" if STILL_MODE else ""
    command = (
        f'"{VENV_PATH}" && python SadTalker/inference.py '
        f'--driven_audio "{audio_path}" '
        f'--source_image "{image_path}" '
        f'--checkpoint_dir "{CHECKPOINT_DIR}" '
        f'--result_dir "{result_dir}" '
        f'--pose_style {POSE_STYLE} '
        f'--batch_size {BATCH_SIZE} '
        f'--size {SIZE} '
        f'--expression_scale {EXPRESSION_SCALE} '
        f'--preprocess {PREPROCESS} '
        f'{still_flag}'
    )
    print("–ó–∞–ø—É—Å–∫ SadTalker...")
    try:
        subprocess.run(command, shell=True, check=True, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    except subprocess.CalledProcessError as e:
        print("–û—à–∏–±–∫–∞ SadTalker:", e)
        sys.exit(1)

def find_generated_video(result_dir, image_path, audio_path):
    image_base = os.path.splitext(os.path.basename(image_path))[0]
    audio_base = os.path.splitext(os.path.basename(audio_path))[0]
    possible_names = [
        f"{image_base}#{audio_base}.mp4",
        f"{image_base}##{audio_base}.mp4",
        f"{image_base}##{audio_base}_full.mp4"
    ]
    for name in possible_names:
        candidate = os.path.join(result_dir, name)
        if os.path.isfile(candidate):
            return candidate

    mp4_files = glob.glob(os.path.join(result_dir, "*.mp4"))
    if mp4_files:
        return mp4_files[0]
    raise FileNotFoundError("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ –≤ –ø–∞–ø–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

def compute_lse_d_syncnet(video_path: str, audio_path: str) -> float:
    print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SyncNet –∏–∑ PyPI...")
    try:
        pipeline = SyncNetPipeline(
            s3fd_weights=SFD_WEIGHTS,
            syncnet_weights=SYNCNET_WEIGHTS,
            device="cpu"
        )
        print("–ê–Ω–∞–ª–∏–∑ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏...")
        results = pipeline.inference(video_path=video_path, audio_path=audio_path)
        
        # –†–∞—Å–ø–∞–∫–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        offset_list, confidence_list, min_dist_list, best_conf, best_min_dist, _, success = results
        
        if not success or len(confidence_list) == 0:
            print("SyncNet: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ (–≤–æ–∑–º–æ–∂–Ω–æ, –Ω–µ—Ç –ª–∏—Ü–∞)")
            return float('inf')
        
        confidence = confidence_list[0]
        print(f"SyncNet (PyPI): confidence = {confidence:.4f}")
        
        # LSE-D: –º–µ–Ω—å—à–µ ‚Äî –ª—É—á—à–µ
        # –í –æ—Ä–∏–≥–∏–Ω–∞–ª–µ: confidence ~ [0, 10+] ‚Üí –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–æ [0, 1]
        lse_d = 1.0 - min(1.0, max(0.0, confidence / 10.0))
        return float(lse_d)
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ syncnet-python: {e}")
        return float('inf')

# === –û—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Ç–æ–∫ ===
if __name__ == "__main__":
    print("=" * 60)
    print("–¢–ï–°–¢ SADTALKER + LSE-D (SyncNet-PyPI)")
    print("=" * 60)

    run_sadtalker(SOURCE_IMAGE_PATH, AUDIO_PATH, RESULT_DIR)

    try:
        video_file = find_generated_video(RESULT_DIR, SOURCE_IMAGE_PATH, AUDIO_PATH)
        print("–ù–∞–π–¥–µ–Ω–æ –≤–∏–¥–µ–æ:", video_file)
    except FileNotFoundError as e:
        print(e)
        for f in os.listdir(RESULT_DIR):
            print("  -", f)
        sys.exit(1)

    print("\n–í—ã—á–∏—Å–ª–µ–Ω–∏–µ LSE-D —á–µ—Ä–µ–∑ SyncNet (PyPI)...")
    lse_score = compute_lse_d_syncnet(video_file, AUDIO_PATH)
    print(f"\nLSE-D –°–∫–æ—Ä: {lse_score:.4f}")
    print("  –ú–µ–Ω—å—à–µ = –ª—É—á—à–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è")
    print("  –•–æ—Ä–æ—à–æ: < 0.3, –ü–ª–æ—Ö–æ: > 0.5")

    results = pd.DataFrame([{
        'image_path': SOURCE_IMAGE_PATH,
        'audio_path': AUDIO_PATH,
        'video_path': video_file,
        'lse_d_syncnet': lse_score,
        'timestamp': datetime.now().isoformat()
    }])
    results.to_csv("sadtalker_lse_syncnet_results.csv", index=False, encoding='utf-8')
    print("\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: sadtalker_lse_syncnet_results.csv")